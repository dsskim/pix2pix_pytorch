{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import functools\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UnetGenerator:\n\tMissing key(s) in state_dict: \"model.model.1.model.2.weight\", \"model.model.1.model.2.bias\", \"model.model.1.model.2.running_mean\", \"model.model.1.model.2.running_var\", \"model.model.1.model.2.num_batches_tracked\", \"model.model.1.model.3.model.2.weight\", \"model.model.1.model.3.model.2.bias\", \"model.model.1.model.3.model.2.running_mean\", \"model.model.1.model.3.model.2.running_var\", \"model.model.1.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.6.weight\", \"model.model.1.model.3.model.6.bias\", \"model.model.1.model.3.model.6.running_mean\", \"model.model.1.model.3.model.6.running_var\", \"model.model.1.model.3.model.6.num_batches_tracked\", \"model.model.1.model.6.weight\", \"model.model.1.model.6.bias\", \"model.model.1.model.6.running_mean\", \"model.model.1.model.6.running_var\", \"model.model.1.model.6.num_batches_tracked\". \n\tUnexpected key(s) in state_dict: \"model.model.0.bias\", \"model.model.1.model.1.bias\", \"model.model.1.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.3.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.5.bias\", \"model.model.1.model.5.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0f3eb08e435e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_G\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unet_256'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gen_param.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    828\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 830\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    831\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UnetGenerator:\n\tMissing key(s) in state_dict: \"model.model.1.model.2.weight\", \"model.model.1.model.2.bias\", \"model.model.1.model.2.running_mean\", \"model.model.1.model.2.running_var\", \"model.model.1.model.2.num_batches_tracked\", \"model.model.1.model.3.model.2.weight\", \"model.model.1.model.3.model.2.bias\", \"model.model.1.model.3.model.2.running_mean\", \"model.model.1.model.3.model.2.running_var\", \"model.model.1.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.3.model.6.weight\", \"model.model.1.model.3.model.3.model.6.bias\", \"model.model.1.model.3.model.3.model.6.running_mean\", \"model.model.1.model.3.model.3.model.6.running_var\", \"model.model.1.model.3.model.3.model.6.num_batches_tracked\", \"model.model.1.model.3.model.6.weight\", \"model.model.1.model.3.model.6.bias\", \"model.model.1.model.3.model.6.running_mean\", \"model.model.1.model.3.model.6.running_var\", \"model.model.1.model.3.model.6.num_batches_tracked\", \"model.model.1.model.6.weight\", \"model.model.1.model.6.bias\", \"model.model.1.model.6.running_mean\", \"model.model.1.model.6.running_var\", \"model.model.1.model.6.num_batches_tracked\". \n\tUnexpected key(s) in state_dict: \"model.model.0.bias\", \"model.model.1.model.1.bias\", \"model.model.1.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.1.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.3.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.3.model.5.bias\", \"model.model.1.model.3.model.5.bias\", \"model.model.1.model.5.bias\". "
     ]
    }
   ],
   "source": [
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the Unet submodule with skip connection.\n",
    "        X -------------------identity----------------------\n",
    "        |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet submodule with skip connections.\n",
    "        Parameters:\n",
    "            outer_nc (int) -- the number of filters in the outer conv layer\n",
    "            inner_nc (int) -- the number of filters in the inner conv layer\n",
    "            input_nc (int) -- the number of channels in input images/features\n",
    "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
    "            outermost (bool)    -- if this module is the outermost module\n",
    "            innermost (bool)    -- if this module is the innermost module\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "        \"\"\"\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Create a Unet-based generator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet generator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
    "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
    "            ngf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "        We construct the U-Net from the innermost layer to the outermost layer.\n",
    "        It is a recursive process.\n",
    "        \"\"\"\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
    "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                nn.init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            nn.init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>\n",
    "    \n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
    "    Parameters:\n",
    "        net (network)      -- the network to be initialized\n",
    "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Return an initialized network.\n",
    "    \"\"\"\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        # net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "    init_weights(net, init_type, init_gain=init_gain)\n",
    "    return net\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    \"\"\"Return a normalization layer\n",
    "    Parameters:\n",
    "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
    "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
    "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
    "    \"\"\"\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'none':\n",
    "        def norm_layer(x): return Identity()\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a generator\n",
    "    Parameters:\n",
    "        input_nc (int) -- the number of channels in input images\n",
    "        output_nc (int) -- the number of channels in output images\n",
    "        ngf (int) -- the number of filters in the last conv layer\n",
    "        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
    "        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
    "        use_dropout (bool) -- if use dropout layers.\n",
    "        init_type (str)    -- the name of our initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Returns a generator\n",
    "    Our current implementation provides two types of generators:\n",
    "        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
    "        The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
    "        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
    "        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
    "        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
    "    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netG == 'unet_128':\n",
    "        net = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    elif netG == 'unet_256':\n",
    "        net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    else:\n",
    "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "g = define_G(3, 3, 64, 'unet_256', 'batch', False, 'normal', 0.02, [0])\n",
    "g.load_state_dict(torch.load('gen_param.pth'))\n",
    "g.eval()\n",
    "\n",
    "from torchscope import scope\n",
    "scope(g, input_size=(3, 256, 256), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/facades/test\\\\1.jpg',\n",
       " 'datasets/facades/test\\\\10.jpg',\n",
       " 'datasets/facades/test\\\\100.jpg',\n",
       " 'datasets/facades/test\\\\101.jpg',\n",
       " 'datasets/facades/test\\\\102.jpg',\n",
       " 'datasets/facades/test\\\\103.jpg',\n",
       " 'datasets/facades/test\\\\104.jpg',\n",
       " 'datasets/facades/test\\\\105.jpg',\n",
       " 'datasets/facades/test\\\\106.jpg',\n",
       " 'datasets/facades/test\\\\11.jpg',\n",
       " 'datasets/facades/test\\\\12.jpg',\n",
       " 'datasets/facades/test\\\\13.jpg',\n",
       " 'datasets/facades/test\\\\14.jpg',\n",
       " 'datasets/facades/test\\\\15.jpg',\n",
       " 'datasets/facades/test\\\\16.jpg',\n",
       " 'datasets/facades/test\\\\17.jpg',\n",
       " 'datasets/facades/test\\\\18.jpg',\n",
       " 'datasets/facades/test\\\\19.jpg',\n",
       " 'datasets/facades/test\\\\2.jpg',\n",
       " 'datasets/facades/test\\\\20.jpg',\n",
       " 'datasets/facades/test\\\\21.jpg',\n",
       " 'datasets/facades/test\\\\22.jpg',\n",
       " 'datasets/facades/test\\\\23.jpg',\n",
       " 'datasets/facades/test\\\\24.jpg',\n",
       " 'datasets/facades/test\\\\25.jpg',\n",
       " 'datasets/facades/test\\\\26.jpg',\n",
       " 'datasets/facades/test\\\\27.jpg',\n",
       " 'datasets/facades/test\\\\28.jpg',\n",
       " 'datasets/facades/test\\\\29.jpg',\n",
       " 'datasets/facades/test\\\\3.jpg',\n",
       " 'datasets/facades/test\\\\30.jpg',\n",
       " 'datasets/facades/test\\\\31.jpg',\n",
       " 'datasets/facades/test\\\\32.jpg',\n",
       " 'datasets/facades/test\\\\33.jpg',\n",
       " 'datasets/facades/test\\\\34.jpg',\n",
       " 'datasets/facades/test\\\\35.jpg',\n",
       " 'datasets/facades/test\\\\36.jpg',\n",
       " 'datasets/facades/test\\\\37.jpg',\n",
       " 'datasets/facades/test\\\\38.jpg',\n",
       " 'datasets/facades/test\\\\39.jpg',\n",
       " 'datasets/facades/test\\\\4.jpg',\n",
       " 'datasets/facades/test\\\\40.jpg',\n",
       " 'datasets/facades/test\\\\41.jpg',\n",
       " 'datasets/facades/test\\\\42.jpg',\n",
       " 'datasets/facades/test\\\\43.jpg',\n",
       " 'datasets/facades/test\\\\44.jpg',\n",
       " 'datasets/facades/test\\\\45.jpg',\n",
       " 'datasets/facades/test\\\\46.jpg',\n",
       " 'datasets/facades/test\\\\47.jpg',\n",
       " 'datasets/facades/test\\\\48.jpg',\n",
       " 'datasets/facades/test\\\\49.jpg',\n",
       " 'datasets/facades/test\\\\5.jpg',\n",
       " 'datasets/facades/test\\\\50.jpg',\n",
       " 'datasets/facades/test\\\\51.jpg',\n",
       " 'datasets/facades/test\\\\52.jpg',\n",
       " 'datasets/facades/test\\\\53.jpg',\n",
       " 'datasets/facades/test\\\\54.jpg',\n",
       " 'datasets/facades/test\\\\55.jpg',\n",
       " 'datasets/facades/test\\\\56.jpg',\n",
       " 'datasets/facades/test\\\\57.jpg',\n",
       " 'datasets/facades/test\\\\58.jpg',\n",
       " 'datasets/facades/test\\\\59.jpg',\n",
       " 'datasets/facades/test\\\\6.jpg',\n",
       " 'datasets/facades/test\\\\60.jpg',\n",
       " 'datasets/facades/test\\\\61.jpg',\n",
       " 'datasets/facades/test\\\\62.jpg',\n",
       " 'datasets/facades/test\\\\63.jpg',\n",
       " 'datasets/facades/test\\\\64.jpg',\n",
       " 'datasets/facades/test\\\\65.jpg',\n",
       " 'datasets/facades/test\\\\66.jpg',\n",
       " 'datasets/facades/test\\\\67.jpg',\n",
       " 'datasets/facades/test\\\\68.jpg',\n",
       " 'datasets/facades/test\\\\69.jpg',\n",
       " 'datasets/facades/test\\\\7.jpg',\n",
       " 'datasets/facades/test\\\\70.jpg',\n",
       " 'datasets/facades/test\\\\71.jpg',\n",
       " 'datasets/facades/test\\\\72.jpg',\n",
       " 'datasets/facades/test\\\\73.jpg',\n",
       " 'datasets/facades/test\\\\74.jpg',\n",
       " 'datasets/facades/test\\\\75.jpg',\n",
       " 'datasets/facades/test\\\\76.jpg',\n",
       " 'datasets/facades/test\\\\77.jpg',\n",
       " 'datasets/facades/test\\\\78.jpg',\n",
       " 'datasets/facades/test\\\\79.jpg',\n",
       " 'datasets/facades/test\\\\8.jpg',\n",
       " 'datasets/facades/test\\\\80.jpg',\n",
       " 'datasets/facades/test\\\\81.jpg',\n",
       " 'datasets/facades/test\\\\82.jpg',\n",
       " 'datasets/facades/test\\\\83.jpg',\n",
       " 'datasets/facades/test\\\\84.jpg',\n",
       " 'datasets/facades/test\\\\85.jpg',\n",
       " 'datasets/facades/test\\\\86.jpg',\n",
       " 'datasets/facades/test\\\\87.jpg',\n",
       " 'datasets/facades/test\\\\88.jpg',\n",
       " 'datasets/facades/test\\\\89.jpg',\n",
       " 'datasets/facades/test\\\\9.jpg',\n",
       " 'datasets/facades/test\\\\90.jpg',\n",
       " 'datasets/facades/test\\\\91.jpg',\n",
       " 'datasets/facades/test\\\\92.jpg',\n",
       " 'datasets/facades/test\\\\93.jpg',\n",
       " 'datasets/facades/test\\\\94.jpg',\n",
       " 'datasets/facades/test\\\\95.jpg',\n",
       " 'datasets/facades/test\\\\96.jpg',\n",
       " 'datasets/facades/test\\\\97.jpg',\n",
       " 'datasets/facades/test\\\\98.jpg',\n",
       " 'datasets/facades/test\\\\99.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_FOLDER = 'datasets/facades/test'\n",
    "img_paths = glob(os.path.join(IMAGE_FOLDER, '*.jpg'))\n",
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "reverse_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=(-1.0, -1.0, -1.0), std=(2, 2, 2)),\n",
    "        transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "os.makedirs('test_img', exist_ok=True)\n",
    "\n",
    "for i, path in enumerate(img_paths):\n",
    "    img = Image.open(path)\n",
    "    in_img = img.crop((img.size[0] // 2, 0, img.size[0], img.size[1]))\n",
    "    out_img = img.crop((0, 0, img.size[0] // 2, img.size[1]))\n",
    "    \n",
    "    in_img = transform(in_img).unsqueeze(0).to(device)\n",
    "    pred = g(in_img)\n",
    "    \n",
    "    in_img = reverse_transform(in_img.squeeze().cpu())\n",
    "    pred_img = reverse_transform(pred.squeeze().cpu())\n",
    "    \n",
    "    whole_img = Image.new('RGB', (in_img.width * 3, in_img.height))\n",
    "    whole_img.paste(in_img, (0, 0))\n",
    "    whole_img.paste(pred_img, (in_img.width, 0))\n",
    "    whole_img.paste(out_img, (in_img.width * 2, 0))\n",
    "    \n",
    "    whole_img.save('test_img/{}.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python361064bitpytorchconda43c42d4fa9cc4e02b919c05bfe4d6e47"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
